Metadata-Version: 2.1
Name: document-polluter
Version: 0.0.2
Summary: Pollutes documents with terms biased on specific geners
Home-page: https://github.com/gregology/document-polluter
Author: Greg Clarke
Author-email: greg@gho.st
License: MIT
Description: # Document Polluter
        
        ## Overview
        
        Document Polluter replaces gendered words in documents to create test data for machine learning models in order to identify bias.
        
        ## Installation
        
        `document-polluter` is available on PyPI
        
        http://pypi.python.org/pypi/document-polluter
        
        ### Install via pip
        
        `$ pip install document-polluter`
        
        ### Install via easy_install
        
        `$ easy_install document-polluter`
        
        ### Install from repo
        
        `git repo <https://github.com/gregology/document-polluter>`
        
        ```
        $ git clone --recursive git://github.com/gregology/document-polluter.git
        $ cd document-polluter
        $ python setup.py install
        ```
        
        ## Basic usage
        
        ```
        >>> from document_polluter import DocumentPolluter
        >>> documents = ['she shouted', 'my son', 'the parent']
        >>> dp = DocumentPolluter(documents=documents, genre='gender')
        >>> print(dp.polluted_documents['female'])
        ['she shouted', 'my daughter', 'the mother']
        ```
        
        ## Running Test
        
        `$ python document_polluter/tests.py `
Keywords: stop words machine learning ml bias biased natural language processing nlp
Platform: UNKNOWN
Classifier: Development Status :: 4 - Beta
Classifier: Intended Audience :: Developers
Classifier: Topic :: Software Development :: Build Tools
Classifier: License :: OSI Approved :: MIT License
Classifier: Programming Language :: Python
Description-Content-Type: text/markdown

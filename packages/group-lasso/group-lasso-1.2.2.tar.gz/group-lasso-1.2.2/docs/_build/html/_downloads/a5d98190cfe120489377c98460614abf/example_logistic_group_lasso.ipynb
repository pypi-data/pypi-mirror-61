{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\nA sample script that runs group lasso for logistic regression.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from group_lasso import LogisticGroupLasso\nfrom utils import (\n    get_groups_from_group_sizes,\n    generate_group_lasso_coefficients,\n)\nimport group_lasso._singular_values\nimport group_lasso._group_lasso\nimport numpy as np\n\n\ngroup_lasso._singular_values._DEBUG = True\ngroup_lasso._group_lasso._DEBUG = True\nLogisticGroupLasso.LOG_LOSSES = True\n\n\nif __name__ == \"__main__\":\n    import matplotlib.pyplot as plt\n\n    np.random.seed(0)\n\n    group_sizes = [np.random.randint(5, 15) for i in range(50)]\n    groups = get_groups_from_group_sizes(group_sizes)\n    num_coeffs = sum(group_sizes)\n    num_datapoints = 100000\n    noise_level = 1\n    coeff_noise_level = 0.05\n\n    print(\"Generating data\")\n    X = np.random.randn(num_datapoints, num_coeffs)\n    intercept = 2\n\n    print(\"Generating coefficients\")\n    w1 = generate_group_lasso_coefficients(group_sizes)\n    w2 = generate_group_lasso_coefficients(group_sizes)\n    w = np.hstack((w1, w2))\n    w += np.random.randn(*w.shape) * coeff_noise_level\n\n    print(\"Generating logits\")\n    y = X @ w\n    y += np.random.randn(*y.shape) * noise_level * y\n    y += intercept\n\n    print(\"Generating targets\")\n    p = 1 / (1 + np.exp(-y))\n    z = np.random.binomial(1, p)\n\n    print(\"Starting fit\")\n    gl = LogisticGroupLasso(\n        groups=groups,\n        n_iter=100,\n        tol=1e-8,\n        group_reg=1e-3,\n        l1_reg=1e-3,\n        subsampling_scheme=1,\n        fit_intercept=True,\n    )\n    gl.fit(X, z)\n\n    for i in range(w.shape[1]):\n        plt.figure()\n        plt.plot(w[:, i], \".\", label=\"True weights\")\n        plt.plot(gl.coef_[:, i], \".\", label=\"Estimated weights\")\n        plt.legend()\n\n    for i in range(w.shape[1]):\n        plt.figure()\n        plt.plot(\n            w[:, i] / np.linalg.norm(w[:, i]),\n            \".\",\n            label=\"Normalised true weights\",\n        )\n        plt.plot(\n            gl.coef_[:, i] / np.linalg.norm(gl.coef_[:, i]),\n            \".\",\n            label=\"Normalised estimated weights\",\n        )\n        plt.legend()\n\n    plt.figure()\n    plt.plot(gl.losses_)\n    plt.title(\"Loss curve\")\n    plt.xlabel(\"Iteration\")\n    plt.ylabel(\"Loss\")\n\n    plt.figure()\n    plt.plot(np.arange(1, len(gl.losses_)), gl.losses_[1:])\n    plt.title(\"Loss curve, ommitting first iteration\")\n    plt.xlabel(\"Iteration\")\n    plt.ylabel(\"Loss\")\n\n    plt.figure()\n    plt.plot([w.min(), w.max()], [gl.coef_.min(), gl.coef_.max()], \"gray\")\n    plt.scatter(w, gl.coef_, s=10)\n    plt.ylabel(\"Learned coefficients\")\n    plt.xlabel(\"True coefficients\")\n\n    print(\"X shape: {shape}\".format(shape=X.shape))\n    print(\"Transformed X shape: {shape}\".format(shape=gl.transform(X).shape))\n    print(\"True intercept: {intercept}\".format(intercept=intercept))\n    print(\"Estimated intercept: {intercept}\".format(intercept=gl.intercept_))\n    print(\"Accuracy: {accuracy}\".format(accuracy=np.mean(z == gl.predict(X))))\n    plt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\nA sample script for group lasso regression\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from group_lasso import GroupLasso\nfrom group_lasso.utils import extract_ohe_groups\nfrom utils import (\n    get_groups_from_group_sizes,\n    generate_group_lasso_coefficients,\n)\nimport numpy as np\nfrom scipy import sparse\nfrom sklearn.preprocessing import OneHotEncoder\nimport matplotlib.pyplot as plt\n\n\nGroupLasso.LOG_LOSSES = True\n\n\nif __name__ == \"__main__\":\n    np.random.seed(1)\n\n    num_categories = 20\n    min_options = 2\n    max_options = 10\n    num_datapoints = 10000\n    noise_level = 1\n    coeff_noise_level = 0.2\n\n    print(\"Generating data\")\n    X_cat = np.empty((num_datapoints, num_categories))\n    for i in range(num_categories):\n        X_cat[:,  i] = np.random.randint(min_options, max_options, num_datapoints)\n\n    ohe = OneHotEncoder()\n    X = ohe.fit_transform(X_cat)\n    groups = extract_ohe_groups(ohe)\n    group_sizes = [np.sum(groups == g) for g in np.unique(groups)]\n    group_weights = [np.random.randint(0, 2) for _ in np.unique(groups)]\n\n    intercept = 2\n\n    print(\"Generating coefficients\")\n    w = np.concatenate(\n        [weight*np.random.standard_normal(group_size) for weight, group_size in zip(group_weights, group_sizes)]\n    ).reshape(-1, 1)\n    w *= np.random.random((len(w), 1)) > 0.4\n    w += np.random.randn(*w.shape) * coeff_noise_level\n\n    print(\"Generating targets\")\n    y = X @ w\n    y += np.random.randn(*y.shape) * noise_level * y\n    y += intercept\n\n    gl = GroupLasso(\n        groups=groups,\n        n_iter=1000,\n        tol=1e-3,\n        l1_reg=0,\n        group_reg=0.02,\n        frobenius_lipschitz=False,\n        subsampling_scheme=None,\n        fit_intercept=True,\n    )\n    print(\"Starting fit\")\n    gl.fit(X, y)\n\n    for i in range(w.shape[1]):\n        plt.figure()\n        plt.subplot(211)\n        plt.plot(w[:, i], \".\", label=\"True weights\")\n        plt.plot(gl.coef_[:, i], \".\", label=\"Estimated weights\")\n\n        plt.subplot(212)\n        plt.plot(w[gl.sparsity_mask, i], \".\", label=\"True weights\")\n        plt.plot(gl.coef_[gl.sparsity_mask, i], \".\", label=\"Estimated weights\")\n        plt.legend()\n\n    plt.figure()\n    plt.plot([w.min(), w.max()], [gl.coef_.min(), gl.coef_.max()], \"gray\")\n    plt.scatter(w, gl.coef_, s=10)\n    plt.ylabel(\"Learned coefficients\")\n    plt.xlabel(\"True coefficients\")\n\n    plt.figure()\n    plt.plot(gl.losses_)\n\n    print(\"X shape: {X.shape}\".format(X=X))\n    print(\"Transformed X shape: {shape}\".format(shape=gl.transform(X).shape))\n    print(\"True intercept: {intercept}\".format(intercept=intercept))\n    print(\"Estimated intercept: {intercept}\".format(intercept=gl.intercept_))\n    plt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
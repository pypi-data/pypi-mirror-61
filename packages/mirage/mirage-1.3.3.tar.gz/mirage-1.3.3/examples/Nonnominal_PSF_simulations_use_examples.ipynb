{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulating Images with Nonnominal PSFs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a significant part of the JWST commissioning process (until around MIMF-3, expected L+118 days), the JWST OTE will not be optimally aligned. The mirrors will be unstacked and unphased, and thus the nominal JWST PSFs that MIRaGe uses when creating imaging simulations do not adequately represent this type of telescope state.\n",
    "\n",
    "In this notebook, we demonstrate how to use MIRaGe to simulate early commissioning images using nonnominal PSFs. The process is as follows:\n",
    "- Parse APT output files to access the details and structure of a given program.\n",
    "- Generate PSF libraries for the desired mirror state for each visit/exposure in a given observation, using `webbpsf` or existing FITS files.\n",
    "- Generate MIRaGe YAML input files that include the directory in which to find the the nonnominal PSF libraries.\n",
    "- Generate seed images from those YAML files that use the appropriate PSF library for the desired exposures. Follow the nominal procedures for adding dark exposure and detector effects.\n",
    "\n",
    "### Table of Contents:\n",
    "1. [Export program information from APT](#export_apt)\n",
    "2. [Create diverse PSF library files](#create_psfs)\n",
    "3. [Create `.yaml` files for each exposure](#make_yamls)\n",
    "4. [Generate the simulated image](#simulate_images)\n",
    "\n",
    "Appendix A: [Generating data for an entire observation](#simulate_whole_obs)\n",
    "\n",
    "Appendix B: [Combining data into a mosaic](#mosaic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import necessary packages and modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Library Imports\n",
    "from glob import glob\n",
    "import os\n",
    "import pprint\n",
    "import shutil\n",
    "import time\n",
    "\n",
    "# Third Party Imports\n",
    "from astropy.io import fits\n",
    "from matplotlib import cm\n",
    "from matplotlib.colors import LogNorm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pysiaf\n",
    "import webbpsf\n",
    "\n",
    "# Local Imports (from nircam_simulator package)\n",
    "from mirage import imaging_simulator\n",
    "from mirage.apt import apt_inputs\n",
    "from mirage.catalogs import get_catalog\n",
    "from mirage.utils.utils import ensure_dir_exists\n",
    "from mirage.yaml import yaml_generator\n",
    "\n",
    "# View matplotlib plots inline\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='export_apt'></a>\n",
    "# 1. Export Program Information from APT\n",
    "\n",
    "MIRaGe requires APT program output files in order to generate data with nonnominal PSFs.\n",
    "\n",
    "### Get needed files from APT program\n",
    "\n",
    "Open the APT file for the program you want to simulate. If you don't have the file locally, you can load this program in APT by selecting `File > Retrieve from STScI > Retrieve Using Proposal ID` and then entering the program ID (e.g. 1140). (You must be running APT in STScI mode for this retrieval method to be available.)\n",
    "\n",
    "Export the `.pointing` and `.xml` files for your given proposal in APT by selecting `File > Export...` and selecting both the xml and pointing file options.\n",
    "\n",
    "For this example, we will simulate images from OTE-17: Image Stacking 2. In this stage of commissioning, the 18 mirror segments are being moved to transition from a hexagonal image array to 17 stacked segments with one kicked out. We will only look at observation 1, for brevity's sake. The neccessary files, `OTE17-1153-obs1only.pointing` and `OTE17-1153-obs1only.xml`, are located within the `examples/nonnominal_psf_data/` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the proposal ID\n",
    "prop_id = 1153\n",
    "\n",
    "# Where the pointing and XML file for this particular OTE CAR are located\n",
    "input_dir = './nonnominal_psf_data/'\n",
    "\n",
    "# Change the root if you named your files differently.\n",
    "root = 'OTE17-{}-obs1only'.format(prop_id)\n",
    "pointing_file = os.path.join(input_dir, '{}.pointing'.format(root))\n",
    "xml_file = os.path.join(input_dir, '{}.xml'.format(root))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define location of output files\n",
    "\n",
    "The process of generating simulated images with MIRaGe produces a lot of files:\n",
    "- YAML files carrying the OTE mirror state\n",
    "- YAML files carrying the specifications for simulations\n",
    "- FITS files of the simulated seed, dark, and compiled images\n",
    "\n",
    "Additionally, we must create FITS library files of the segment PSF images in order to simulate images with nonnominal PSFs.\n",
    "\n",
    "Let's define the directories to save these output files to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Where to save MIRaGe output\n",
    "out_dir = './nonnominal_psf_data/output/'\n",
    "\n",
    "# Where the segment PSF library files will be saved to (and later read from)\n",
    "library_dir = os.path.join(out_dir, 'gridded_psf_library')\n",
    "\n",
    "# Make sure both these directories exist\n",
    "for full_path in [out_dir, library_dir]:\n",
    "    ensure_dir_exists(full_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse the `.pointing` file to get the number of PSF libraries needed\n",
    "\n",
    "As mentioned above, we'll use the infrastructure of observation 1 in OTE-17: Image Stacking 2 (program 1153) for this example. \n",
    "\n",
    "This observation is a WFSC Commissioning observation that includes 17 Wavefront Control (WFC) groups to bring the mirrors in. (17 sets of image-mirror move-image plus 1 additional image.)\n",
    "\n",
    "So, in order to generate the YAML configuration files for program 1153 observation 1, MIRaGe will need 18 different PSF libraries representing the 18 different mirror states across OTE-17 Observation 1. \n",
    "\n",
    "We can parse the `.pointing` file to verify this number:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the information from the pointing file\n",
    "apt_prop = apt_inputs.AptInput()\n",
    "pointing_tab = apt_prop.get_pointing_info(pointing_file, '1153')\n",
    "n_exposures = len(pointing_tab['visit_id'])\n",
    "print('MIRaGe requires PSFs for {} exposures.'.format(len(pointing_tab['visit_id'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='create_psfs'></a>\n",
    "# 2. Create unique, nonnominal PSF library files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will outline two methods you can use to create an image with MIRaGe using unique PSFs for each exposure:\n",
    "- If you have a list of **mirror moves/positions** describing different telescope states throughout different observations/visits, use [option 1](#adjustable_ote). We will use `webbpsf` to generate PSFs and then gridded PSF library objects from those telescope states.\n",
    "- If you have a list of pre-existing **FITS files** with PSFs from different telescope states throughout different observations/visits, use [option 2](#to_model)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Organizing PSF files\n",
    "\n",
    "For every exposure simulation, MIRaGe will use the PSF library defined by the `psf_path` argument of that exposure's YAML file. So, to create a MIRaGe simulation with a nonnominal PSF, you must provide a path other than the default to the `psf_path` argument.\n",
    "\n",
    "Thus, the easiest way to specify 18 different PSFs to be used for 18 different exposures is to:\n",
    "1. Save each unique PSF library in a different directory\n",
    "2. Pass an ordered list of the 18 separate directories to the YAML generator\n",
    "\n",
    "There are a number of ways you could do the first step above, but here we choose to:\n",
    "1. Generate a nested directory structure that matches the program structure\n",
    "2. Save each PSF into the corresponding directory (i.e. `Observation001/Visit002/Activity03/PSFLibrary.fits`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create dictionary that mirrors the program structure\n",
    "program_structure = {}\n",
    "for i in range(n_exposures):\n",
    "    obs_num = pointing_tab['obs_num'][i]\n",
    "    visit_num = pointing_tab['visit_num'][i]\n",
    "    activity_id = pointing_tab['act_id'][i]\n",
    "    \n",
    "    obs_key = 'Observation{}'.format(obs_num)\n",
    "    visit_key = 'Visit{}'.format(visit_num)\n",
    "    \n",
    "    program_structure.setdefault(obs_key, {})\n",
    "    visit_dict = program_structure[obs_key].setdefault(visit_key, []).append('Activity{}'.format(activity_id))                                                                      \n",
    "    \n",
    "pprint.pprint(program_structure)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create directory structure based on dictionary\n",
    "psf_paths = []\n",
    "program_dir = os.path.join(library_dir, root)\n",
    "for observation in program_structure.keys():\n",
    "    for visit in program_structure[observation].keys():\n",
    "        for activity in program_structure[observation][visit]:\n",
    "            activity_dir = os.path.join(program_dir, observation, visit, activity)\n",
    "            ensure_dir_exists(activity_dir)\n",
    "            psf_paths.append(activity_dir)\n",
    "            \n",
    "pprint.pprint(glob(program_dir + '/**/', recursive=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='adjustable_ote'></a>\n",
    "### Option 1: Use `webbpsf.enable_adjustable_ote()` to make a different PSF for each exposure\n",
    "\n",
    "In this case, we use `webbpsf` to simulate 18 PSFs, 1 for each exposure, each of which have their own unique mirror state.\n",
    "\n",
    "We will start with a image array (downgrading from large to medium for computational time), not yet coarsely phased. Then, we will bring one mirror segment in at a time for each of the 18 exposures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate starting PSF: a large image array with random pistons.\n",
    "\n",
    "# Initialize the webbpsf NIRCam object and turn on adjustable mirrors\n",
    "nc = webbpsf.NIRCam()\n",
    "nc, ote = webbpsf.enable_adjustable_ote(nc)\n",
    "\n",
    "# Set up a large image array with random pistons.\n",
    "webbpsf.opds.setup_image_array(ote, reset=True, verbose=False, size='medium')\n",
    "\n",
    "# Add random pistons\n",
    "random_pistons = np.random.randn(18)*20  # substantial coarse phasing erorrs. \n",
    "for i, seg in enumerate(ote.segnames[0:18]):  # don't piston \"segment 19\" the SM\n",
    "    ote.move_seg_local(seg, piston=random_pistons[i])\n",
    "    \n",
    "# Define the image size (here, 1024 x 1024 pixels)\n",
    "fov_pixels = 1024\n",
    "\n",
    "# Generate the PSF\n",
    "# NOTE: we are choosing a polychromatic simulation here to better represent the\n",
    "# complexity of simulating unstacked PSFs. See the WebbPSF website for more details.\n",
    "original_psf = nc.calc_psf(nlambda=10, oversample=1, \n",
    "                           fov_pixels=fov_pixels, add_distortion=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the starting PSF\n",
    "plt.imshow(original_psf[1].data, norm=LogNorm(), clim=(1e-10, 1e-5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mirror moves to bring the segments back in\n",
    "tilt_correction = []\n",
    "for i, segment in enumerate(ote.segment_state):\n",
    "    xtilt = segment[0]\n",
    "    ytilt = segment[1]\n",
    "    tilt_correction.append((i, -xtilt, -ytilt))\n",
    "pprint.pprint(tilt_correction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_psf_lib_for_ote(nc, ote, i_exposure, pointing_table, psf_paths, \n",
    "                           tilt, fov_pixels):\n",
    "    \"\"\"For a given exposure in an APT program, perturb an OTE state \n",
    "    according to the corresponding X & Y tilt, and generate \n",
    "    and save a gridded PSF library using that perturbed mirror state.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    nc : webbpsf.webbpsf_core.NIRCam instance\n",
    "        WebbPSF NIRCam instrument instance\n",
    "    ote : webbpsf.opds.OTE_Linear_Model_WSS object\n",
    "        Starting mirror state\n",
    "    i_exposure : int\n",
    "        The index of the exposure (starting at 0)\n",
    "    pointing_tab : dict\n",
    "        Dictionary containing information parsed from APT .pointing file\n",
    "    psf_paths : list\n",
    "        List of paths to the directories where each of the PSF libraries \n",
    "        (one per exposure) will be saved\n",
    "    tilt : list\n",
    "        List of tuples containing the X and Y tilts to apply to the \n",
    "        mirror state for each exposure\n",
    "    fov_pixels : int\n",
    "        The size of one side of the square output PSF library, in pixels\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    psf_dir = psf_paths[i_exposure]\n",
    "    \n",
    "    print('Calculating PSF for obs {}, visit {}, exposure {}'\n",
    "          .format(pointing_table['obs_num'][i_exposure], \n",
    "                  pointing_table['visit_num'][i_exposure], \n",
    "                  i_exposure + 1))\n",
    "\n",
    "    i_seg, x_tilt_corr, y_tilt_corr = tilt[i_exposure]\n",
    "    ote.move_seg_local(ote.segnames[i_seg], xtilt=x_tilt_corr, ytilt=y_tilt_corr)\n",
    "    nc.pupil = ote\n",
    "    \n",
    "    # Define the filter\n",
    "    nc.filter = 'F212N'\n",
    "    nc.detector = 'NRCA3'\n",
    "    \n",
    "    # Write out file\n",
    "    filename = 'nircam_fovp{}_samp1_npsf1.fits'.format(fov_pixels)\n",
    "    outfile = os.path.abspath(os.path.join(psf_dir, filename))\n",
    "    print(outfile)\n",
    "\n",
    "    # Generate the PSF grid\n",
    "    grid = nc.psf_grid(num_psfs=1, save=True, all_detectors=False,\n",
    "                       use_detsampled_psf=True, fov_pixels=fov_pixels,\n",
    "                       oversample=1, outfile=outfile, add_distortion=False,\n",
    "                       nlambda=10)\n",
    "    \n",
    "    print('Elapsed time: {}\\n'.format(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "    \n",
    "<b>Warning:</b> <br>\n",
    "\n",
    "The for loop below will take a while: about 5 seconds for a 1024x1024 array, per detector, per filter! We've written it so that it will only write out for NIRCam A3 with the F212N filter, but know that if you need to generate more PSFs for different telescope states, detectors, and filters, this simulation might take quite a while.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Run create_psf_lib_for_ote() for each of the 18 exposures in OTE-17 Observation 1\n",
    "for i_exposure in range(n_exposures):\n",
    "    create_psf_lib_for_ote(nc, ote, i_exposure, pointing_tab, psf_paths, \n",
    "                           tilt_correction, fov_pixels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='to_model'></a>\n",
    "### Option 2: Use pre-existing FITS file as PSF for each visit\n",
    "\n",
    "In this case, we assume you have pre-existing PSF fits files stored somewhere (e.g. ITM simulations) that you want to MIRaGe to use.\n",
    "\n",
    "(To be clear, the process below is not a continuation of [Option 1](#adjustable_ote), but a separate process that would be run instead.)\n",
    "\n",
    "Thus, we must copy these pre-existing FITS files into the program directory structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: you must have access to the STScI central storage directories to use these data.\n",
    "psf_fits_data_dir = '/grp/jwst/ote/mirage_example_data/'\n",
    "all_ote17_fits = sorted(glob(psf_fits_data_dir + '*.fits'))\n",
    "all_ote17_fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just for fun, plot all the data\n",
    "fig, axes = plt.subplots(3, 6, figsize=(15, 8))\n",
    "plt.tight_layout()\n",
    "\n",
    "i = 1\n",
    "for ax, f in zip(axes.flatten(), all_ote17_fits):\n",
    "    with fits.open(f) as hdulist:\n",
    "        psf_data = hdulist[1].data\n",
    "    ax.imshow(psf_data, clim=(0.1, 100))\n",
    "    ax.set_title('Exposure {}'.format(i))\n",
    "    i += 1\n",
    "        \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Copy the images into the observation/visit/activity-specific directories\n",
    "for psf_path, fits_file in zip(psf_paths, all_ote17_fits):\n",
    "    shutil.copy(fits_file, psf_path)\n",
    "    print('Copied PSF to: {}'.format(os.path.abspath(os.path.join(psf_path, os.path.basename(fits_file)))))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='make_yamls'></a>\n",
    "# 3. Create YAML files for each exposure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to make the YAML files that include all of the parameters for MIRaGe to run.\n",
    "\n",
    "Here we will provide the MIRaGe YAML generator with an ordered list of each PSF path we filled above, i.e.: \n",
    "\n",
    "    [Observation001/Visit001/Activity01/', 'Observation001/Visit001/Activity02/', ...]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query online catalogs to generate catalog files of sources around the target star\n",
    "\n",
    "Next, we need to generate catalog files containing RA, Dec, and magnitude for the sources around the target (or targets) in this proposal. \n",
    "\n",
    "First we must parse the `.pointing` file to determine the RA and Dec of the target (or targets) that will be observed. Then we will query the appropriate star catalogs to get the magnitudes and locations of shortwave and longwave sources, respectively, around the target(s). If you are using F212N and F480M NIRCam filters, you can use the 2MASS and WISE catalogs, respectively. If you are using one of these two filters, all of this can be accomplished with the `mirage.get_catalog.get_all_catalogs` function.  \n",
    "\n",
    "If different observations within the proposal have different targets, separate catalogs will be made for each target.\n",
    "\n",
    "These catalog files will be written to your local `mirage/catalogs/` directory. If files for a given catalog and RA/Dec have already been generated, they will not be regenerated.\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "    \n",
    "<b>Important:</b> <br>\n",
    "\n",
    "Querying 2MASS and WISE is only appropriate for observations with the F212N and F480M NIRCam filters. If you want to simulate observations that use other filters, you will have to either query different bandpasses or catalogs or perform a photometric conversion on an existing catalog.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate and save shortwave and longwave individual catalogs for the target stars\n",
    "cats = get_catalog.get_all_catalogs(pointing_file, prop_id)\n",
    "target_coords, catalog_filenames_sw, catalog_filenames_lw = cats\n",
    "\n",
    "cat_dict = {'nircam': {'lw': catalog_filenames_lw,\n",
    "                       'sw': catalog_filenames_sw}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate the `.yaml` files\n",
    "\n",
    "MIRaGe's YAML generator,`mirage.yaml.yaml_generator`, will create all of the YAML files for a whole APT program at once - one YAML file per exposure in the program.\n",
    "\n",
    "**Some additional settings are required to ensure `yaml_generator` works for nonnominal PSF simulations.** You must specify theses attribute before running `create_inputs()` to make the YAML files correctly:\n",
    "- `yam.psf_paths = [list or str]` - tells MIRaGe to use files in the given directory/directories for the PSFs paths for different exposures. `psf_paths` can be defined as:\n",
    "    - *A string pointing to a directory* - the matching PSF library in that directory will be written into ALL YAMLs, and thus will be used for ALL exposures in the program\n",
    "    - *A list of strings pointing to a list of directories* - Each directory in the list will be mapped onto the corresponding YAML, in chronological order: the 0th listed directory will be used for the 0th exposure/YAML, the 1st listed directory for the 1st exposure/YAML, and so on. Thus each exposure will be simulated using its respective, potentially different, PSF library. The list must be the same length as the number of exposures in the program.\n",
    "    <br><br>\n",
    "- `yam.add_psf_wings = False` - tells MIRaGe not to add wings to the PSF. We don't need wings in this case, since our PSFs are so large.\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Create all input YAML files (one per each exposure)\n",
    "yaml_dir = os.path.join(out_dir, 'yamls')\n",
    "yam = yaml_generator.SimInput(input_xml=xml_file, pointing_file=pointing_file,\n",
    "                              catalogs=cat_dict,\n",
    "                              verbose=True, output_dir=yaml_dir, simdata_output_dir=out_dir)\n",
    "yam.psf_paths = psf_paths\n",
    "yam.add_psf_wings = False\n",
    "yam.create_inputs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose which exposure to simulate\n",
    "\n",
    "Now that we've generated all of the needed YAML files, we need to choose one to simulate images with. MIRaGE can only generate one simulated exposure at a time, so we need to choose one YAML file in our `yamls` directory that we will use to produce an image. (See [Appendix A](#simulate_whole_obs) for how use a wrapper to simulate multiple exposures at once with MIRaGe.)\n",
    "\n",
    "Not every exposure necessarily has the same pointing, so we should choose an exposure that places the target star in the desired detector field-of-view."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examine target pointings relative to apertures and V2/V3 references\n",
    "\n",
    "Looking at the `.pointing` file, let's plot where the target will appear relative to the NIRCam apertures for each unique pointing.\n",
    "\n",
    "We'll also print out the first YAML in the exposure list for each pointing. In this case, this just means printing out the first YAML, since there is only one pointing across all the exposures. However, if you are plotting the pointings for an observation that contains more than one pointing, then another YAML file will be added to the \"Example files for each pointing:\" list, corresponding to the exposure when the pointing changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Examine apertures and V2/V3 references for each array/subarray\n",
    "nc_siaf = pysiaf.Siaf('NIRCam')\n",
    "nc_full = nc_siaf['NRCA1_FULL']\n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "for apername in sorted(nc_siaf.apernames):\n",
    "    a = apername\n",
    "    if ('_FULL' in a) and ('OSS' not in a) and ('MASK' not in a) and (a[-1] != 'P'):\n",
    "        nc_siaf[a].plot(frame='tel', label=a, fill_color='white')\n",
    "\n",
    "# Compare V2/V3 of targets (from .pointing file)\n",
    "all_pointings = set([(v2, v3, filename) for v2, v3, filename in zip(yam.info['v2'], \n",
    "                                                                yam.info['v3'], \n",
    "                                                                yam.info['yamlfile'])])\n",
    "\n",
    "print('Example files for each pointing:')\n",
    "print('--------------------------------')\n",
    "plotted_points = []\n",
    "for i_point, (v2, v3, filename) in enumerate(all_pointings):\n",
    "    if (v2, v3) not in plotted_points:\n",
    "        plotted_points.append((v2, v3))\n",
    "        plt.scatter(v2, v3, marker='*', s=500, \n",
    "                    label='Pointing {}/{}'.format(i_point + 1, len(all_pointings)))\n",
    "        print('{}. {}'.format(i_point + 1, filename))\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is easy for 1153 Obs. 1, since all 18 exposures have the same pointing. We'll just choose a YAML that has a detector and filter that matches the library files we have created so far - NRCA3 and F212N.\n",
    "\n",
    "Let's choose `jw01153001001_01101_00001_nrca3.yaml`.\n",
    "\n",
    "*See [JDox](https://jwst-docs.stsci.edu/display/JDAT/File+Naming+Conventions+and+Data+Products) for a detailed explanation of the MIRaGE YAML file name format.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select one YAML where the target will be in the field of view\n",
    "yfiles = glob(os.path.join(yaml_dir, '*.yaml'))\n",
    "file_name_to_match = 'jw01153001001_01101_00001_nrca3'\n",
    "yaml_to_sim = os.path.abspath([y for y in yfiles if file_name_to_match in y][0])\n",
    "print(yaml_to_sim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='simulate_images'></a>\n",
    "# 4. Simulate image with MIRaGe\n",
    "\n",
    "Finally, we can run MIRaGe to generate a seed image simulation of our unstacked mirror state during OTE-17.\n",
    "\n",
    "From here on out, from the user perspective, the simulation process is identical to that of nominal imaging cases (see the [imaging example notebook](#Imaging_simulator_use_examples.ipynb). To reiterate, it is the specifications made in the YAML files that enable the simulation of nonnominal mirror simulations with MIRaGe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Run the image simulator using the input defined in yaml_to_sim\n",
    "img_sim = imaging_simulator.ImgSim()\n",
    "img_sim.paramfile = yaml_to_sim\n",
    "img_sim.create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the seed image, dark image, and final exposure simulation\n",
    "fig, [ax1, ax2, ax3] = plt.subplots(1, 3, figsize=(20, 7))\n",
    "plt.tight_layout()\n",
    "\n",
    "# Define scale limits and colormap\n",
    "clim = (1e-2, 1e4)\n",
    "cmap = cm.get_cmap('viridis')\n",
    "cmap.set_bad(cmap(0))\n",
    "\n",
    "# Plot seed image\n",
    "fitsplot = ax1.imshow(img_sim.seedimage, clim=clim, norm=LogNorm(), cmap=cmap)\n",
    "ax1.set_title('Seed Image', size=24)\n",
    "\n",
    "# Plot dark current\n",
    "dark_diff = img_sim.linDark.data[0,-1,:,:] - img_sim.linDark.data[0,0,:,:]\n",
    "ax2.imshow(dark_diff, \n",
    "           clim=clim, norm=LogNorm())\n",
    "ax2.set_title('Dark Current', size=24)\n",
    "\n",
    "# Plot final exposure\n",
    "linear_output = './nonnominal_psf_data/output/jw01153001001_01101_00001_nrca3_linear.fits'\n",
    "with fits.open(linear_output) as h:\n",
    "    lindata = h[1].data\n",
    "    header = h[0].header\n",
    "exptime = header['EFFINTTM']\n",
    "diffdata = (lindata[0,-1,:,:] - lindata[0,0,:,:]) / exptime\n",
    "\n",
    "ax3.imshow(diffdata, clim=clim, norm=LogNorm())\n",
    "ax3.set_title('Final Exposure Simulation', size=24)\n",
    "\n",
    "# Define the colorbar\n",
    "cbar_ax = fig.add_axes([1, 0.09, 0.03, 0.87])\n",
    "cbar = plt.colorbar(fitsplot, cbar_ax)\n",
    "cbar.set_label('Count Rate', rotation=270, labelpad=30, size=24)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "---\n",
    "<a id='simulate_whole_obs'></a>\n",
    "# Appendix A: Simulating many exposures at once\n",
    "\n",
    "Chances are, you don't want to simulate just one exposure from one detector. In order to simulate all of the exposures from a given observation, write a for loop to iterate over all the YAMLs. We include an example for program 1134 observation 1 below.\n",
    "\n",
    "### 1. Create all PSF library files\n",
    "First, make sure that you have created library files for all of the filters and detectors that will be simulated in your observation. (This might mean continuing [step 2](#create_psfs) above.)\n",
    "\n",
    "### 2. Run `imaging_simulator` for all YAMLs\n",
    "Second, grab all of the YAMLs for that observation and run the image simulator on them all.\n",
    "```python\n",
    "from glob import glob\n",
    "import os\n",
    "\n",
    "from mirage import imaging_simulator\n",
    "\n",
    "# Get all the 1153 Obs 1 yamls\n",
    "all_yaml_files = glob(os.path.join(yaml_dir, 'jw01153001*.yaml'))\n",
    "n_yamls = len(all_yaml_files)\n",
    "print('{} FITS files will be generated.'.format(n_yamls))\n",
    "\n",
    "for yaml in all_yaml_files:\n",
    "    print('*** SIMULATING YAML {}/{}: {} ***'.format(i+1, n_yamls, yaml))\n",
    "    img_sim = imaging_simulator.ImgSim()\n",
    "    img_sim.paramfile = yaml\n",
    "    img_sim.create()\n",
    "```\n",
    "\n",
    "(If you are impatient and ambitious, you can use Python's `multiprocessing` module to the simulation go faster. Even better on a server with more processors!)\n",
    "\n",
    "To learn how to combine multiple exposure simulations into a mosaic with QUIP, see [Appendix B](#mosaic)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "---\n",
    "<a id='mosaic'></a>\n",
    "# Appendix B: Combine into a mosaic\n",
    "\n",
    "The [`wss_tools`](https://wss-tools.readthedocs.io/en/latest/) include a software program, QUIP, which can be used to combine a list of FITS files into a single mosaic image. QUIP requires an operations file, which we describe how to make here.\n",
    "\n",
    "### Turn linear FITS products into slope images\n",
    "```python\n",
    "from glob import glob\n",
    "import os\n",
    "\n",
    "from astropy.io import fits\n",
    "\n",
    "from mirage.utils.utils import ensure_dir_exists\n",
    "\n",
    "obs1_fits = glob(os.path.join(out_dir, 'jw*linear.fits'))\n",
    "print('{} FITS files produced for program APT 1153 Observation 1'.format(len(obs1_fits)))\n",
    "\n",
    "# Subtract the first from last for each ramp\n",
    "for f in obs1_fits:\n",
    "    with fits.open(f) as hdulist:\n",
    "        data = hdulist[1].data\n",
    "        hdr = hdulist[1].header\n",
    "        \n",
    "    diff = data[0, -1] - data[0, 0]\n",
    "\n",
    "    hdu = fits.PrimaryHDU(data=diff, header=hdr)\n",
    "\n",
    "    new_filename = os.path.join(out_dir, 'slope_fits', os.path.basename(f))\n",
    "    ensure_dir_exists(os.path.dirname(new_filename))\n",
    "    hdu.writeto(new_filename, overwrite=True)\n",
    "    \n",
    "obs1_slope_fits = glob(os.path.join(out_dir, 'slope_fits', 'jw*linear.fits'))\n",
    "```\n",
    "\n",
    "\n",
    "### Make ops file for QUIP\n",
    "```python\n",
    "# Set variables for writing QUIP ops file\n",
    "quip_dir = os.path.join(out_dir, 'quip')\n",
    "ensure_dir_exists(quip_dir)\n",
    "outfile = 'congrid'\n",
    "bindim = 2048\n",
    "opsfile = os.path.join(quip_dir, 'ops_file_'+outfile.strip(\"/\")+str(bindim)+'.xml')\n",
    "\n",
    "# Write the file\n",
    "f = open(opsfile, 'w')\n",
    "\n",
    "f.write('<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"yes\"?>\\n')\n",
    "f.write('<QUIP_OPERATION_FILE xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" creator=\"WSS Executive\" time=\"16:22:40.093Z\" date=\"2017-06-14Z\" version=\"6.0.1\" operational=\"false\" xsi:noNamespaceSchemaLocation=\"/Users/lajoie/TEL/WSS-6.0.1/Software/schema/quip_operation_file.xsd\">\\n')\n",
    "f.write('    <CORRECTION_ID>R2017061401</CORRECTION_ID>\\n')\n",
    "f.write('    <OPERATION_TYPE>THUMBNAIL</OPERATION_TYPE>\\n')\n",
    "f.write('    <IMAGES>\\n')\n",
    "\n",
    "for filename in obs1_slope_fits:\n",
    "    f.write(\"       <IMAGE_PATH>{:s}</IMAGE_PATH>\\n\".format(filename))\n",
    "    \n",
    "f.write( '       </IMAGES>\\n'    )\n",
    "f.write( '       <OUTPUT>\\n')\n",
    "f.write( '           <OUTPUT_DIRECTORY>{:s}quip/</OUTPUT_DIRECTORY>\\n'.format(quip_dir))\n",
    "f.write( '           <LOG_FILE_PATH>{:s}quip/R2017061401_quip_activity_log.xml</LOG_FILE_PATH>\\n'.format(quip_dir))\n",
    "f.write( '           <OUT_FILE_PATH>{:s}quip/R2017061401_quip_out.xml</OUT_FILE_PATH>\\n'.format(quip_dir))\n",
    "f.write( '       </OUTPUT>\\n')\n",
    "\n",
    "f.write('</QUIP_OPERATION_FILE>\\n')\n",
    "\n",
    "f.close()\n",
    "\n",
    "print('Successfully wrote QUIP ops file to', opsfile)\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
